
Epoch 1/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:03<00:00, 39.55it/s]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.46it/s]
Epoch 0/20
	Train Loss 12.2130	 Learning Rate 0.0001600
	Val Loss 10.0298

Epoch 2/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.76it/s]
Epoch 1/20
	Train Loss 4.3243	 Learning Rate 0.0014942
	Val Loss 0.4327

Epoch 3/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.65it/s]
Epoch 2/20
	Train Loss 0.3497	 Learning Rate 0.0036426
	Val Loss 0.3325

Epoch 4/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.13it/s] 
Epoch 3/20
	Train Loss 0.3142	 Learning Rate 0.0039950
	Val Loss 0.3059

Epoch 5/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.51it/s]
Epoch 4/20
	Train Loss 0.2860	 Learning Rate 0.0039558
	Val Loss 0.2936

Epoch 6/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 43.11it/s]
Epoch 5/20
	Train Loss 0.2814	 Learning Rate 0.0038786
	Val Loss 0.2831

Epoch 7/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.73it/s]
Epoch 6/20
	Train Loss 0.2531	 Learning Rate 0.0037648
	Val Loss 0.2264

Epoch 8/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 41.83it/s]
Epoch 7/20
	Train Loss 0.2490	 Learning Rate 0.0036167
	Val Loss 0.2206

Epoch 9/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:03<00:00, 38.90it/s] 
Epoch 8/20
	Train Loss 0.2396	 Learning Rate 0.0034371
	Val Loss 0.2235

Epoch 10/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.07it/s] 
Epoch 9/20
	Train Loss 0.2483	 Learning Rate 0.0032295
	Val Loss 0.2235

Epoch 11/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.26it/s] 
Epoch 10/20
	Train Loss 0.2297	 Learning Rate 0.0029980
	Val Loss 0.2141

Epoch 12/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.95it/s]
Epoch 11/20
	Train Loss 0.2136	 Learning Rate 0.0027471
	Val Loss 0.1983

Epoch 13/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.21it/s]
Epoch 12/20
	Train Loss 0.2140	 Learning Rate 0.0024816
	Val Loss 0.1955

Epoch 14/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.42it/s]
Epoch 13/20
	Train Loss 0.1898	 Learning Rate 0.0022068
	Val Loss 0.1632

Epoch 15/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.89it/s]
Epoch 14/20
	Train Loss 0.1860	 Learning Rate 0.0019279
	Val Loss 0.1773

Epoch 16/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.43it/s]
Epoch 15/20
	Train Loss 0.1758	 Learning Rate 0.0016505
	Val Loss 0.1605

Epoch 17/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.42it/s]
Epoch 16/20
	Train Loss 0.1857	 Learning Rate 0.0013798
	Val Loss 0.1665

Epoch 18/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.48it/s]
Epoch 17/20
	Train Loss 0.1829	 Learning Rate 0.0011212
	Val Loss 0.1629

Epoch 19/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.43it/s]
Epoch 18/20
	Train Loss 0.1803	 Learning Rate 0.0008797
	Val Loss 0.1662

Epoch 20/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.67it/s] 
Epoch 19/20
	Train Loss 0.1751	 Learning Rate 0.0006601
	Val Loss 0.1718

Epoch 21/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 42.21it/s]
Epoch 20/20
	Train Loss 0.1676	 Learning Rate 0.0004665
	Val Loss 0.1669

Epoch 22/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:03<00:00, 40.43it/s]
Epoch 21/20
	Train Loss 0.1809	 Learning Rate 0.0003027
	Val Loss 0.1606

Epoch 23/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:03<00:00, 40.04it/s] 
Epoch 22/20
	Train Loss 0.1693	 Learning Rate 0.0001720
	Val Loss 0.1563

Epoch 24/25
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:02<00:00, 41.05it/s] 
Epoch 23/20
	Train Loss 0.1669	 Learning Rate 0.0000769
	Val Loss 0.1638

Epoch 25/25
                                                            
Epoch 24/20
	Train Loss 0.1723	 Learning Rate 0.0000192
	Val Loss 0.1653
32
----------------------------------------------------------------------------------------------------
Layer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)
====================================================================================================
0_Linear                     [3, 30]             [32, 30]                 0.12                 0.00
1_ReLU                             -             [32, 30]                    -                    -
2_BatchNorm1d                   [30]             [32, 30]                 0.06                 0.00
3_Linear                    [30, 30]             [32, 30]                 0.93                 0.00
4_ReLU                             -             [32, 30]                    -                    -
5_BatchNorm1d                   [30]             [32, 30]                 0.06                 0.00
6_Linear                    [30, 30]             [32, 30]                 0.93                 0.00
7_ReLU                             -             [32, 30]                    -                    -
8_BatchNorm1d                   [30]             [32, 30]                 0.06                 0.00
9_Linear                    [30, 30]             [32, 30]                 0.93                 0.00
10_ReLU                            -             [32, 30]                    -                    -
11_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
12_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
13_ReLU                            -             [32, 30]                    -                    -
14_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
15_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
16_ReLU                            -             [32, 30]                    -                    -
17_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
18_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
19_ReLU                            -             [32, 30]                    -                    -
20_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
21_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
22_ReLU                            -             [32, 30]                    -                    -
23_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
24_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
25_ReLU                            -             [32, 30]                    -                    -
26_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
27_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
28_ReLU                            -             [32, 30]                    -                    -
29_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
30_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
31_ReLU                            -             [32, 30]                    -                    -
32_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
33_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
34_ReLU                            -             [32, 30]                    -                    -
35_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
36_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
37_ReLU                            -             [32, 30]                    -                    -
38_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
39_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
40_ReLU                            -             [32, 30]                    -                    -
41_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
42_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
43_ReLU                            -             [32, 30]                    -                    -
44_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
45_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
46_ReLU                            -             [32, 30]                    -                    -
47_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
48_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
49_ReLU                            -             [32, 30]                    -                    -
50_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
51_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
52_ReLU                            -             [32, 30]                    -                    -
53_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
54_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
55_ReLU                            -             [32, 30]                    -                    -
56_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
57_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
58_ReLU                            -             [32, 30]                    -                    -
59_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
60_Linear                   [30, 30]             [32, 30]                 0.93                 0.00
61_ReLU                            -             [32, 30]                    -                    -
62_BatchNorm1d                  [30]             [32, 30]                 0.06                 0.00
63_Linear                    [30, 1]              [32, 1]                 0.03                 0.00
====================================================================================================
# Params:    20.01K
# Mult-Adds: 0.02M
----------------------------------------------------------------------------------------------------
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
